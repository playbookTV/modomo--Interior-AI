Perfect. Here‚Äôs a breakdown of all three deliverables tailored for your current Modomo test phase:

‚∏ª

üß™ 1. Modomo Testing Webapp ‚Äì PRD (Product Requirements Document)

Objective

Build an internal webapp for testing AI models that generate enhanced interior designs from uploaded images. This tool will help evaluate the performance of model training, object generation, and tagging accuracy.

Core Flow
	1.	User uploads an image of a real room.
	2.	Model processes the image to enhance it ‚Äî e.g., by adding decor, furniture, lighting, or stylistic changes.
	3.	Output image is displayed, showing new visual elements added by the model.
	4.	User clicks on objects in the image to:
	‚Ä¢	View object metadata (name, type).
	‚Ä¢	See price and purchase options (dummy data for now).

Features

üîπ MVP
	‚Ä¢	Secure image upload (drag & drop or file picker)
	‚Ä¢	Display model-enhanced image
	‚Ä¢	Clickable bounding boxes or regions
	‚Ä¢	Metadata tooltip or sidebar (name, style, price)
	‚Ä¢	Log inference details for debugging

üîπ Admin-only Tools
	‚Ä¢	View model parameters used
	‚Ä¢	Re-run model with different styles/prompts
	‚Ä¢	Toggle layers (original / generated / mask / tags)

Tech Stack (Suggested)
	‚Ä¢	Frontend: React + TailwindCSS (or Preact)
	‚Ä¢	Backend: FastAPI or Node (with Docker)
	‚Ä¢	Storage: S3 / Cloudflare R2 / local dev
	‚Ä¢	Model Inference: Runpod or Lambda Labs
	‚Ä¢	Model Backend: ControlNet + Stable Diffusion or custom LoRA

‚∏ª

üñºÔ∏è 2. Dataset Strategy for Interior Image Scraping

Goal

Gather high-quality, diverse interior design images for:
	‚Ä¢	Training the generation model
	‚Ä¢	Object detection and segmentation
	‚Ä¢	Style transfer accuracy

Sources

Source	Type	Notes
Pinterest	High-res lifestyle shots	Use Puppeteer + proxy rotation
Houzz	Styled room photos	Requires dynamic scraping
Behance	Designer portfolios	Can use open API or headless scrape
IKEA, Wayfair	Product scenes	Good for labeled room setups
ArchDaily	Architecture-focused	Include minimal and modern interiors
Unsplash/Pexels	Free stock	Use for generic spaces
Reddit	r/InteriorDesign, r/malelivingspace	Raw user-uploaded setups

Scraping Strategy
	‚Ä¢	Use Scrapy or Puppeteer + rotating proxies (Zyte, ScraperAPI)
	‚Ä¢	Store:
	‚Ä¢	image_url
	‚Ä¢	style_tag (if available or inferred later)
	‚Ä¢	room_type (living, kitchen, bedroom)
	‚Ä¢	objects_in_scene (optional)
	‚Ä¢	Avoid watermarked/duplicate images

‚∏ª

üß† 3. Model Training Plan (Phase 1 ‚Äì Object Identification + Generation)

Training Goal

Train a model (or chain of models) to:
	1.	Understand indoor scenes
	2.	Replace/enhance objects
	3.	Generate click-tag data with bounding boxes and metadata

‚∏ª

Model Stack (Suggested)

üîπ A. Scene Understanding
	‚Ä¢	Model: YOLOv8, Grounding DINO or SAM (Segment Anything)
	‚Ä¢	Task: Detect layout + existing furniture

üîπ B. Image Generation
	‚Ä¢	Model: ControlNet + SDXL or Style-LoRA
	‚Ä¢	Task: Add furniture based on style prompt
	‚Ä¢	Training: Fine-tune LoRA on scraped datasets (with ControlNet hints)

üîπ C. Object Metadata Extraction
	‚Ä¢	Bounding Box Mapping: Store object ID + coordinates + metadata
	‚Ä¢	Use heatmaps or feature attribution for clickable mapping

‚∏ª

Training Tools
	‚Ä¢	Annotation: Label Studio or CVAT
	‚Ä¢	Training: ü§ó Diffusers + DreamBooth/LoRA for SD
	‚Ä¢	Infrastructure: Runpod (GPU 3090/4090), Dockerized Jupyter setup
	‚Ä¢	Logging: Weights & Biases or TensorBoard

‚∏ª

üìà Evaluation
	‚Ä¢	Track image enhancement quality (side-by-side comparisons)
	‚Ä¢	Measure:
	‚Ä¢	Object diversity
	‚Ä¢	Tagging accuracy
	‚Ä¢	Visual appeal (manual + CLIP scores)

‚∏ª
